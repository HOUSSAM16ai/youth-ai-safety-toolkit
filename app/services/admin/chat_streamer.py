"""
Ø¨Ø« Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ (Admin Chat Streamer).

Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø¯Ù…Ø© Ù…Ø³Ø¤ÙˆÙ„Ø© Ø¹Ù† Ø¥Ø¯Ø§Ø±Ø© ØªØ¯ÙÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­ÙŠØ© Ø¹Ø¨Ø± WebSocket Ø¨ÙŠÙ† Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©
ÙˆÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„.

Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©:
- **Async Iteration**: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆÙ„Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØºÙŠØ± Ù…Ø­Ø¬ÙˆØ¨Ø©.
- **Fail Fast**: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø£Ø­Ø¯Ø§Ø« Ø®Ø·Ø£ ÙˆØ§Ø¶Ø­Ø© Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©.
- **Strict Typing**: Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Python 3.12+.
"""

from __future__ import annotations

import asyncio
import logging
from collections.abc import AsyncGenerator, Callable

from sqlalchemy.ext.asyncio import AsyncSession

from app.core.ai_gateway import AIClient
from app.core.domain.chat import AdminConversation, MessageRole
from app.infrastructure.clients.orchestrator_client import orchestrator_client
from app.services.admin.chat_persistence import AdminChatPersistence
from app.services.chat.contracts import ChatStreamEvent

logger = logging.getLogger(__name__)

# Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¹Ø§Ù„Ù…ÙŠØ© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ© ÙˆÙ…Ù†Ø¹ Ø¬Ù…Ø¹ Ø§Ù„Ù‚Ù…Ø§Ù…Ø© (Garbage Collection)
_background_tasks: set[asyncio.Task[object]] = set()


class AdminChatStreamer:
    """
    Ø¨Ø« Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ (Admin Chat Streamer).
    """

    def __init__(self, persistence: AdminChatPersistence) -> None:
        """
        ØªÙ‡ÙŠØ¦Ø© Ø¨Ø§Ø« Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.

        Args:
            persistence: Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¯Ø§Ø¦Ù… Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª.
        """
        self.persistence = persistence

    async def stream_response(
        self,
        user_id: int,
        conversation: AdminConversation,
        question: str,
        history: list[dict[str, object]],
        ai_client: AIClient,
        session_factory_func: Callable[[], AsyncSession],
        metadata: dict[str, object] | None = None,
    ) -> AsyncGenerator[ChatStreamEvent, None]:
        """
        ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¨Ø« Ø§Ù„Ø­ÙŠ Ù„Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¹Ø¨Ø± OrchestratorClient.

        Yields:
            ChatStreamEvent: Ø£Ø­Ø¯Ø§Ø« WebSocket Ù…Ù†Ø¸Ù…Ø© Ø¹Ù„Ù‰ Ø´ÙƒÙ„ Ù‚Ø§Ù…ÙˆØ³.
        """
        # 1. Ø¥Ø±Ø³Ø§Ù„ Ø­Ø¯Ø« Ø§Ù„ØªÙ‡ÙŠØ¦Ø©
        # 1. ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ§Ø±ÙŠØ® (Ù„Ø¶Ù…Ø§Ù† ØªÙ†Ø§Ø³Ù‚ Ø§Ù„Ø­Ø§Ù„Ø© ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©)
        self._update_history_with_question(history, question)

        yield self._create_init_event(conversation)

        # 2. ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø« Ù…Ø¹ Ø§Ù„Ø­ÙØ¸
        try:
            full_response: list[str] = []

            # Prepare clean history (remove duplicate current question if exists)
            clean_history = [
                {k: str(v) for k, v in m.items()}
                for m in history
                if not (m.get("role") == "user" and m.get("content") == question)
            ]

            async for event in orchestrator_client.chat_with_agent(
                question=question,
                user_id=user_id,
                conversation_id=conversation.id,
                history_messages=clean_history,
                context=metadata,
            ):
                if isinstance(event, dict):
                    # Extract content for persistence
                    evt_type = str(event.get("type", ""))
                    if evt_type in ("assistant_delta", "delta"):
                        content = str(event.get("payload", {}).get("content", ""))
                        if content:
                            full_response.append(content)
                            if self._exceeds_safety_limit(full_response):
                                yield self._create_size_limit_error()
                                break

                    # Compatibility: Map 'assistant_delta' to 'delta' for legacy frontend support
                    if evt_type == "assistant_delta":
                        event["type"] = "delta"

                    yield event
                else:
                    # String fallback
                    content = str(event)
                    full_response.append(content)
                    if self._exceeds_safety_limit(full_response):
                        yield self._create_size_limit_error()
                        break
                    yield self._create_chunk_event(content)

            # 3. Ø­ÙØ¸ ÙˆØ¥Ù†Ù‡Ø§Ø¡
            await self._persist_response(conversation.id, full_response, session_factory_func)
            yield {"type": "complete", "payload": {"status": "done"}}

        except Exception as e:
            logger.error(f"ğŸ”¥ Streaming error: {e}", exc_info=True)
            yield self._create_error_event(str(e))

    def _update_history_with_question(
        self, history: list[dict[str, object]], question: str
    ) -> None:
        """
        ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯.
        """
        if not history or history[-1].get("content") != question:
            history.append({"role": "user", "content": question})

    def _create_init_event(self, conversation: AdminConversation) -> ChatStreamEvent:
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ø§Ù„ØªÙ‡ÙŠØ¦Ø©.
        """
        init_payload = {
            "conversation_id": conversation.id,
            "title": conversation.title,
        }
        return {"type": "conversation_init", "payload": init_payload}

    def _exceeds_safety_limit(self, response_parts: list[str]) -> bool:
        """
        Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ¬Ø§ÙˆØ² Ø­Ø¯ Ø§Ù„Ø£Ù…Ø§Ù† (100 Ø£Ù„Ù Ø­Ø±Ù).
        """
        current_size = sum(len(x) for x in response_parts)
        return current_size > 100000

    def _create_chunk_event(self, content: str) -> ChatStreamEvent:
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ø¬Ø²Ø¡ Ù…Ø­ØªÙˆÙ‰ (OpenAI style).
        """
        return {"type": "delta", "payload": {"content": content}}

    def _create_size_limit_error(self) -> ChatStreamEvent:
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ø®Ø·Ø£ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¬Ù….
        """
        return {
            "type": "error",
            "payload": {"details": "Response exceeded safety limit (100k chars). Aborting stream."},
        }

    def _create_error_event(self, error_details: str) -> ChatStreamEvent:
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ø§Ù….
        """
        return {"type": "error", "payload": {"details": error_details}}

    async def _persist_response(
        self,
        conversation_id: int,
        response_parts: list[str],
        session_factory_func: Callable[[], AsyncSession],
    ) -> None:
        """
        Ø­ÙØ¸ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
        """
        assistant_content = "".join(response_parts)
        if not assistant_content and not response_parts:
            # Just to ensure we don't save empty string if it was tool calls only
            # But persist history if needed.
            return

        try:
            async with session_factory_func() as session:
                p = AdminChatPersistence(session)
                await p.save_message(conversation_id, MessageRole.ASSISTANT, assistant_content)
            logger.info(f"âœ… Conversation {conversation_id} saved successfully.")
        except Exception as e:
            logger.error(f"âŒ Failed to save assistant message: {e}")
