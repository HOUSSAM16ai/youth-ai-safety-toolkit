from __future__ import annotations

import asyncio
import logging
import time
from collections.abc import AsyncGenerator
from typing import TYPE_CHECKING

from app.core.resilience import get_circuit_breaker
from app.services.chat.handlers.base import ChatContext
from app.services.chat.security import ErrorSanitizer

if TYPE_CHECKING:
    from app.core.ai_gateway import AIClient

logger = logging.getLogger(__name__)


# ======================================================================================
# Helper Functions for Mission Handler
# ======================================================================================
async def _check_preconditions(
    context: ChatContext, user_id: int
) -> AsyncGenerator[str | None, None]:
    """Check rate limits and circuit breaker before mission creation."""
    allowed, msg = await context.check_rate_limit(user_id, "mission")
    if not allowed:
        yield f"âš ï¸ {msg}\n"
        return

    circuit = get_circuit_breaker("mission")
    can_execute, circuit_msg = circuit.can_execute()
    if not can_execute:
        yield f"âš ï¸ Ø§Ù„Ø®Ø¯Ù…Ø© ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ù…Ø¤Ù‚ØªØ§Ù‹: {circuit_msg}\n"
        return

    yield None


async def _create_mission(
    context: ChatContext, objective: str, user_id: int, circuit
) -> dict | None:
    """Create mission with timeout and error handling."""
    try:
        async with asyncio.timeout(15):
            result = await context.async_overmind.start_mission(
                objective=objective, user_id=user_id
            )
        circuit.record_success()
        return result
    except TimeoutError:
        circuit.record_failure()
        return {"ok": False, "error": "timeout"}
    except Exception as e:
        circuit.record_failure()
        return {"ok": False, "error": str(e)}


def _format_task_info(tasks: dict) -> str:
    """Format task progress information."""
    if not tasks:
        return ""

    total = tasks.get("total", 0)
    success = tasks.get("success", 0)
    running = tasks.get("running", 0)
    failed = tasks.get("failed", 0)

    info = f" | Ø§Ù„Ù…Ù‡Ø§Ù…: {success}/{total} âœ…"
    if running:
        info += f" {running} ğŸ”„"
    if failed:
        info += f" {failed} âŒ"
    return info


def _get_status_emoji(status: str) -> str:
    """Get emoji for mission status."""
    return {
        "pending": "â³",
        "planning": "ğŸ“‹",
        "planned": "ğŸ“",
        "running": "ğŸ”„",
        "adapting": "ğŸ”§",
        "success": "âœ…",
        "failed": "âŒ",
        "canceled": "ğŸš«",
    }.get(status, "â“")


async def _poll_mission_status(context: ChatContext, mission_id: int) -> AsyncGenerator[str, None]:
    """Poll mission status until completion or timeout."""
    poll_count = 0
    max_polls = 150  # 150 Ù…Ø­Ø§ÙˆÙ„Ø© Ã— 2 Ø«Ø§Ù†ÙŠØ© = 5 Ø¯Ù‚Ø§Ø¦Ù‚
    poll_interval = 2
    last_status = ""
    start_time = time.time()

    # Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    phase_messages = {
        "planning": "ğŸ¯ **Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1/4**: Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ®Ø·ÙŠØ·...",
        "design": "ğŸ“ **Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2/4**: Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØµÙ…ÙŠÙ…...",
        "execution": "âš™ï¸ **Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3/4**: Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ†ÙÙŠØ°...",
        "reflection": "ğŸ” **Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4/4**: Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©...",
        "running": "ğŸ”„ **Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©**...",
        "pending": "â³ **ÙÙŠ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±**...",
    }

    try:
        while poll_count < max_polls:
            await asyncio.sleep(poll_interval)
            poll_count += 1

            try:
                status_result = await context.async_overmind.get_mission_status(mission_id)
            except Exception:
                break

            if not status_result.get("ok"):
                break

            status = status_result.get("status", "unknown")
            tasks = status_result.get("tasks", {})
            is_terminal = status_result.get("is_terminal", False)

            # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠ
            elapsed = int(time.time() - start_time)
            elapsed_str = f"{elapsed}s" if elapsed < 60 else f"{elapsed // 60}m {elapsed % 60}s"

            # Ø¥Ø¸Ù‡Ø§Ø± Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø¥Ø°Ø§ ØªØºÙŠØ±Øª Ø§Ù„Ø­Ø§Ù„Ø©
            if status != last_status:
                phase_msg = phase_messages.get(status.lower(), f"ğŸ“Š **Ø§Ù„Ø­Ø§Ù„Ø©**: {status}")
                yield f"\n{phase_msg} â±ï¸ ({elapsed_str})\n"
                last_status = status

            task_info = _format_task_info(tasks)
            status_emoji = _get_status_emoji(status)

            # Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„ØªÙ‚Ø¯Ù… ÙƒÙ„ 10 polls (20 Ø«Ø§Ù†ÙŠØ©)
            if poll_count % 10 == 0:
                yield f"  â””â”€ {status_emoji} {status}{task_info} â±ï¸ ({elapsed_str})\n"

            if is_terminal:
                final_elapsed = int(time.time() - start_time)
                yield f"\nğŸ **Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø­Ø§Ù„Ø©: {status}** â±ï¸ ({final_elapsed}s)\n"
                break

    except asyncio.CancelledError:
        yield "\nâš ï¸ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©.\n"

    if poll_count >= max_polls:
        elapsed = int(time.time() - start_time)
        yield f"\nâ„¹ï¸ Ø§Ù„Ù…Ù‡Ù…Ø© ØªØ¹Ù…Ù„ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© (Ù‚Ø¶Øª {elapsed}s Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†). ÙŠÙ…ÙƒÙ†Ùƒ Ù…ØªØ§Ø¨Ø¹Ø© Ø­Ø§Ù„ØªÙ‡Ø§ Ù…Ù† Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ….\n"


async def handle_deep_analysis(
    context: ChatContext,
    question: str,
    user_id: int,
    ai_client: AIClient,
) -> AsyncGenerator[str, None]:
    """
    Handle deep analytical questions using Overmind's deep understanding.
    Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Overmind.
    """
    start_time = time.time()

    yield "ğŸ§  **ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Overmind Master Agent**\n\n"

    # 1. Ø¨Ù†Ø§Ø¡ ÙÙ‡Ø±Ø³ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ | Build project index
    summary = await _build_project_index_with_feedback()
    async for feedback in summary["feedback"]:
        yield feedback

    # 2. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù…Ø­Ø³Ù‘Ù† | Create enhanced prompt
    messages = _create_deep_analysis_messages(question, summary["data"])

    # 3. Ø¨Ø« Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© | Stream AI response
    yield "ğŸ’¡ **Ø§Ù„ØªØ­Ù„ÙŠÙ„:**\n\n"

    async for chunk in _stream_ai_analysis(ai_client, messages):
        yield chunk

    logger.debug(f"Deep analysis completed in {(time.time() - start_time) * 1000:.2f}ms")


async def _build_project_index_with_feedback() -> dict[str, object]:
    """
    Ø¨Ù†Ø§Ø¡ ÙÙ‡Ø±Ø³ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù…Ø¹ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù….
    Build project index with user feedback.

    Returns:
        dict: {'data': summary or None, 'feedback': generator of feedback messages}
    """
    feedback_messages = []
    feedback_messages.append("ğŸ“Š Ø¬Ø§Ø±Ù ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚ Ø¹Ù…ÙŠÙ‚...\n")

    try:
        from app.services.overmind.planning.deep_indexer import build_index, summarize_for_prompt

        async def _build_index_async():
            return await asyncio.to_thread(build_index, root=".")

        index = await asyncio.wait_for(_build_index_async(), timeout=30.0)
        summary = summarize_for_prompt(index, max_len=3000)
        feedback_messages.append("âœ… ØªÙ… Ø¨Ù†Ø§Ø¡ ÙÙ‡Ø±Ø³ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹\n\n")

        return {"data": summary, "feedback": _async_generator_from_list(feedback_messages)}

    except TimeoutError:
        feedback_messages.append("âš ï¸ Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„ÙÙ‡Ø±Ø³Ø©ØŒ Ø³Ø£Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ø±ÙØªÙŠ Ø§Ù„Ø­Ø§Ù„ÙŠØ©\n\n")
        return {"data": None, "feedback": _async_generator_from_list(feedback_messages)}

    except Exception as e:
        logger.warning(f"Failed to build index for deep analysis: {e}")
        feedback_messages.append("âš ï¸ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„\n\n")
        return {"data": None, "feedback": _async_generator_from_list(feedback_messages)}


async def _async_generator_from_list(items: list[str]) -> AsyncGenerator[str, None]:
    """
    ØªØ­ÙˆÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø¥Ù„Ù‰ Ù…ÙˆÙ„Ø¯ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†.
    Convert list to async generator.
    """
    for item in items:
        yield item


def _create_deep_analysis_messages(question: str, summary: str | None) -> list[dict[str, str]]:
    """
    Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚.
    Create messages for deep analysis with context.
    """
    system_prompt = """Ø£Ù†Øª Overmind Master Agent - Ù†Ø¸Ø§Ù… Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªÙ‚Ø¯Ù… Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©.

Ù„Ø¯ÙŠÙƒ Ù‚Ø¯Ø±Ø§Øª Ø®Ø§ØµØ©:
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ© ÙˆØ§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©
- ÙÙ‡Ù… Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„ÙˆØ­Ø¯Ø§Øª
- ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯ ÙˆØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ­Ø³ÙŠÙ†
- Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© ÙˆØ§Ù„Ø«ØºØ±Ø§Øª
- ØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª

Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø¹Ù…Ù‚ ÙˆØ§Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ø±ÙØªÙƒ Ø¨Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù„ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø© ÙˆØ¯Ù‚ÙŠÙ‚Ø©."""

    messages = [{"role": "system", "content": system_prompt}]

    if summary:
        context_msg = f"""**Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹:**

{summary}

---

Ø§Ù„Ø¢Ù†ØŒ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø¯Ù‚Ø© ÙˆØ´Ù…ÙˆÙ„ÙŠØ©:

{question}"""
        messages.append({"role": "user", "content": context_msg})
    else:
        messages.append({"role": "user", "content": question})

    return messages


async def _stream_ai_analysis(
    ai_client: AIClient, messages: list[dict[str, str]]
) -> AsyncGenerator[str, None]:
    """
    Ø¨Ø« ØªØ­Ù„ÙŠÙ„ AI.
    Stream AI analysis response with error handling.
    """
    try:
        async for chunk in ai_client.stream_chat(messages):
            if isinstance(chunk, dict):
                content = _extract_content_from_chunk(chunk)
                if content:
                    yield content
            elif isinstance(chunk, str):
                yield chunk
    except Exception as e:
        yield f"\n\nâŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {ErrorSanitizer.sanitize(str(e))}\n"


def _extract_content_from_chunk(chunk: dict) -> str:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ù‚Ø·Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©.
    Extract content from response chunk.
    """
    choices = chunk.get("choices", [])
    if choices:
        return choices[0].get("delta", {}).get("content", "")
    return ""


async def handle_mission(
    context: ChatContext,
    objective: str,
    user_id: int,
    conversation_id: int,
) -> AsyncGenerator[str, None]:
    """
    Handle complex mission request with Overmind and polling.
    DEPRECATED: Super Agent dispatch via monolith HTTP bridge is strictly disabled.
    All mission dispatch must be routed through API Gateway to Orchestrator Service.
    """
    yield "âŒ **Ø®Ø·Ø£ Ù…Ø¹Ù…Ø§Ø±ÙŠ:** ØªÙ… ØªØ¹Ø·ÙŠÙ„ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ.\n"
    yield "ÙŠØ¬Ø¨ ØªÙˆØ¬ÙŠÙ‡ ÙƒØ§ÙØ© Ø§ØªØµØ§Ù„Ø§Øª WebSocket Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ `orchestrator-service`.\n"
    yield "ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù€ API Gateway."
    return


async def _link_mission_to_conversation(conversation_id: int, mission_id: int):
    """
    Link mission to conversation for tracking.

    Note: Imports are inside method to prevent circular imports.
    This is intentional as this service is loaded early in the app lifecycle.
    """
    try:
        # Lazy imports to prevent circular dependencies - this is intentional
        from app.core.database import SessionLocal
        from app.core.domain.chat import AdminConversation
        from app.services.async_tool_bridge import run_sync_tool

        def _update():
            session = SessionLocal()
            try:
                conv = session.get(AdminConversation, conversation_id)
                if conv and hasattr(conv, "linked_mission_id"):
                    conv.linked_mission_id = mission_id
                    session.commit()
                    return True
            except Exception as e:
                logger.warning(f"Failed to link mission to conversation: {e}")
                session.rollback()
            finally:
                session.close()
            return False

        await run_sync_tool(_update, timeout=5.0)
    except Exception as e:
        logger.warning(f"Failed to link mission {mission_id} to conv {conversation_id}: {e}")
