"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                                          â•‘
â•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â•‘
â•‘  â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â•â•â•      â•‘
â•‘  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—        â•‘
â•‘  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•        â•‘
â•‘  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â•‘
â•‘   â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•šâ•â•      â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•      â•‘
â•‘                                                                                          â•‘
â•‘              ğŸ§  AI MODELS CONFIGURATION CENTER v2.1 - SUPERHUMAN EDITION                â•‘
â•‘              â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                â•‘
â•‘                                                                                          â•‘
â•‘   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—    â•‘
â•‘   â•‘  ğŸ“ THIS IS THE ONLY FILE YOU NEED TO EDIT TO CHANGE AI MODELS                â•‘    â•‘
â•‘   â•‘  ğŸ“ Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù…Ù„Ù Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø°ÙŠ ØªØ­ØªØ§Ø¬ ØªØ¹Ø¯ÙŠÙ„Ù‡ Ù„ØªØºÙŠÙŠØ± Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ         â•‘    â•‘
â•‘   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â•‘
â•‘                                                                                          â•‘
â•‘   ğŸ”§ HOW TO CHANGE MODELS | ÙƒÙŠÙÙŠØ© ØªØºÙŠÙŠØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬:                                        â•‘
â•‘      1. Scroll down to "ACTIVE CONFIGURATION" section                                   â•‘
â•‘      2. Change the model values directly                                                â•‘
â•‘      3. Save the file and restart the application                                       â•‘
â•‘                                                                                          â•‘
â•‘      1. Ø§Ù†Ø²Ù„ Ø¥Ù„Ù‰ Ù‚Ø³Ù… "ACTIVE CONFIGURATION"                                             â•‘
â•‘      2. ØºÙŠÙ‘Ø± Ù‚ÙŠÙ… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø©                                                          â•‘
â•‘      3. Ø§Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙˆØ£Ø¹Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚                                                    â•‘
â•‘                                                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

from __future__ import annotations

from dataclasses import dataclass
from functools import lru_cache

from .config import get_settings
from .logging import get_logger

logger = get_logger(__name__)


class AvailableModels:
    """
    ğŸ“š All Available AI Models | Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©

    Copy the model ID (the string value) to use in the configuration below.
    Ø§Ù†Ø³Ø® Ù…Ø¹Ø±Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù†ØµÙŠØ©) Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙÙŠ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø£Ø¯Ù†Ø§Ù‡.
    """

    GPT_4O = "openai/gpt-4o"
    GPT_4O_MINI = "openai/gpt-4o-mini"
    GPT_4_TURBO = "openai/gpt-4-turbo"
    GPT_4 = "openai/gpt-4"
    GPT_35_TURBO = "openai/gpt-3.5-turbo"
    CLAUDE_37_SONNET_THINKING = "anthropic/claude-3.7-sonnet:thinking"
    CLAUDE_35_SONNET = "anthropic/claude-3.5-sonnet"
    CLAUDE_OPUS_4_5 = "anthropic/claude-opus-4.5"
    CLAUDE_3_OPUS = "anthropic/claude-3-opus"
    CLAUDE_3_HAIKU = "anthropic/claude-3-haiku"
    GEMINI_PRO = "google/gemini-pro"
    GEMINI_PRO_15 = "google/gemini-pro-1.5"
    LLAMA_3_70B = "meta-llama/llama-3-70b-instruct"
    LLAMA_3_8B = "meta-llama/llama-3-8b-instruct"
    LLAMA_3_2_11B_VISION_FREE = "meta-llama/llama-3.2-11b-vision-instruct:free"
    GEMINI_2_FLASH_EXP_FREE = "google/gemini-2.0-flash-exp:free"
    PHI_3_MINI_FREE = "microsoft/phi-3-mini-128k-instruct:free"
    KAT_CODER_PRO_FREE = "kwaipilot/kat-coder-pro:free"
    QWEN_QWEN3_CODER_FREE = "qwen/qwen3-coder:free"
    DEVSTRAL_2512 = "mistralai/devstral-2512:free"
    GLM_4_5_AIR_FREE = "z-ai/glm-4.5-air:free"
    DEEPSEEK_R1_CHIMERA_FREE = "tngtech/deepseek-r1t2-chimera:free"
    NEMOTRON_3_NANO = "nvidia/nemotron-3-nano-30b-a3b:free"


class ActiveModels:
    """
    âš™ï¸ ACTIVE AI MODELS CONFIGURATION | ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù†Ø´Ø·

    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                                                   â•‘
    â•‘   ğŸ”§ TO CHANGE A MODEL:                                                          â•‘
    â•‘      1. Find the model you want to change below                                  â•‘
    â•‘      2. Replace the value with one from AvailableModels above                    â•‘
    â•‘      3. Save and restart                                                         â•‘
    â•‘                                                                                   â•‘
    â•‘   ğŸ”§ Ù„ØªØºÙŠÙŠØ± Ù†Ù…ÙˆØ°Ø¬:                                                               â•‘
    â•‘      1. Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ ØªØºÙŠÙŠØ±Ù‡ Ø£Ø¯Ù†Ø§Ù‡                                   â•‘
    â•‘      2. Ø§Ø³ØªØ¨Ø¯Ù„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø¨ÙˆØ§Ø­Ø¯Ø© Ù…Ù† AvailableModels Ø£Ø¹Ù„Ø§Ù‡                            â•‘
    â•‘      3. Ø§Ø­ÙØ¸ ÙˆØ£Ø¹Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„                                                        â•‘
    â•‘                                                                                   â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """

    PRIMARY = AvailableModels.NEMOTRON_3_NANO
    LOW_COST = AvailableModels.NEMOTRON_3_NANO
    GATEWAY_PRIMARY = AvailableModels.NEMOTRON_3_NANO
    GATEWAY_FALLBACK_1 = AvailableModels.GEMINI_2_FLASH_EXP_FREE
    GATEWAY_FALLBACK_2 = AvailableModels.QWEN_QWEN3_CODER_FREE
    GATEWAY_FALLBACK_3 = AvailableModels.KAT_CODER_PRO_FREE
    GATEWAY_FALLBACK_4 = AvailableModels.PHI_3_MINI_FREE
    GATEWAY_FALLBACK_5 = AvailableModels.LLAMA_3_2_11B_VISION_FREE
    TIER_NANO = AvailableModels.NEMOTRON_3_NANO
    TIER_FAST = AvailableModels.NEMOTRON_3_NANO
    TIER_SMART = AvailableModels.NEMOTRON_3_NANO
    TIER_GENIUS = AvailableModels.NEMOTRON_3_NANO


@dataclass(frozen=True)
class AIConfig:
    """
    AI Configuration singleton - reads from ActiveModels class.
    """

    primary_model: str = ActiveModels.PRIMARY
    low_cost_model: str = ActiveModels.LOW_COST
    gateway_primary: str = ActiveModels.GATEWAY_PRIMARY
    gateway_fallback_1: str = ActiveModels.GATEWAY_FALLBACK_1
    gateway_fallback_2: str = ActiveModels.GATEWAY_FALLBACK_2
    gateway_fallback_3: str = ActiveModels.GATEWAY_FALLBACK_3
    gateway_fallback_4: str = ActiveModels.GATEWAY_FALLBACK_4
    gateway_fallback_5: str = ActiveModels.GATEWAY_FALLBACK_5
    tier_nano: str = ActiveModels.TIER_NANO
    tier_fast: str = ActiveModels.TIER_FAST
    tier_smart: str = ActiveModels.TIER_SMART
    tier_genius: str = ActiveModels.TIER_GENIUS

    @property
    def openrouter_api_key(self) -> str | None:
        """
        ğŸ”‘ Access API Key securely from the Central Nervous System (Settings).
        ÙŠØ³ØªØ±Ø¬Ø¹ Ù…ÙØªØ§Ø­ API Ø¨Ø£Ù…Ø§Ù† Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ (Settings).
        """
        return get_settings().OPENROUTER_API_KEY

    def get_fallback_models(self) -> list[str]:
        """Get list of fallback models."""
        return [
            self.gateway_fallback_1,
            self.gateway_fallback_2,
            self.gateway_fallback_3,
            self.gateway_fallback_4,
            self.gateway_fallback_5,
        ]

    def to_dict(self) -> dict:
        """Export configuration as dictionary."""
        return {
            "primary_model": self.primary_model,
            "low_cost_model": self.low_cost_model,
            "gateway": {
                "primary": self.gateway_primary,
                "fallback_1": self.gateway_fallback_1,
                "fallback_2": self.gateway_fallback_2,
                "fallback_3": self.gateway_fallback_3,
                "fallback_4": self.gateway_fallback_4,
                "fallback_5": self.gateway_fallback_5,
            },
            "tiers": {
                "nano": self.tier_nano,
                "fast": self.tier_fast,
                "smart": self.tier_smart,
                "genius": self.tier_genius,
            },
        }

    def log_config(self) -> None:
        """Log current configuration."""
        logger.info(
            """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§  CURRENT AI MODELS CONFIGURATION                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"""
        )
        logger.info("â•‘  ğŸ¯ Primary Model:     %s â•‘", f"{self.primary_model:<50}")
        logger.info("â•‘  ğŸ’° Low Cost Model:    %s â•‘", f"{self.low_cost_model:<50}")
        logger.info(
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
        )
        logger.info("â•‘  ğŸŒŸ Gateway Primary:   %s â•‘", f"{self.gateway_primary:<50}")
        logger.info("â•‘  ğŸ”„ Fallback 1:        %s â•‘", f"{self.gateway_fallback_1:<50}")
        logger.info("â•‘  ğŸ”„ Fallback 2:        %s â•‘", f"{self.gateway_fallback_2:<50}")
        logger.info("â•‘  ğŸ”„ Fallback 3:        %s â•‘", f"{self.gateway_fallback_3:<50}")
        logger.info("â•‘  ğŸ”„ Fallback 4:        %s â•‘", f"{self.gateway_fallback_4:<50}")
        logger.info("â•‘  ğŸ”„ Fallback 5:        %s â•‘", f"{self.gateway_fallback_5:<50}")
        logger.info(
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
        )
        logger.info("â•‘  âš¡ Tier NANO:         %s â•‘", f"{self.tier_nano:<50}")
        logger.info("â•‘  ğŸš€ Tier FAST:         %s â•‘", f"{self.tier_fast:<50}")
        logger.info("â•‘  ğŸ§  Tier SMART:        %s â•‘", f"{self.tier_smart:<50}")
        logger.info("â•‘  ğŸ“ Tier GENIUS:       %s â•‘", f"{self.tier_genius:<50}")
        logger.info(
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        )


@lru_cache(maxsize=1)
def get_ai_config() -> AIConfig:
    """Get the AI configuration singleton."""
    return AIConfig()


ai_config = get_ai_config()
__all__ = ["AIConfig", "ActiveModels", "AvailableModels", "ai_config", "get_ai_config"]

if __name__ == "__main__":
    logger.info("ğŸ“‹ Available Models for Reference:")
    logger.info("â”€" * 60)
    logger.info("  OpenAI GPT-4o:           %s", AvailableModels.GPT_4O)
    logger.info("  OpenAI GPT-4o-mini:      %s", AvailableModels.GPT_4O_MINI)
    logger.info("  Claude 3.7 Sonnet:       %s", AvailableModels.CLAUDE_37_SONNET_THINKING)
    logger.info("  Claude 3.5 Sonnet:       %s", AvailableModels.CLAUDE_35_SONNET)
    logger.info("  Claude 3 Opus:           %s", AvailableModels.CLAUDE_3_OPUS)
    logger.info("â”€" * 60)
    config = get_ai_config()
    config.log_config()
